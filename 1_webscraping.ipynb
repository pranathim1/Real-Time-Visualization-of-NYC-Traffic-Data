{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# The URL for the streaming data to be scraped\n",
    "streamPath = 'http://207.251.86.229/nyc-links-cams/LinkSpeedQuery.txt'\n",
    "\n",
    "# The output file for the script\n",
    "# Does not need to be created first\n",
    "outputFilePath = 'C:/Users/Pranathi/Desktop/MSBA/Fall/Harvesting Big Data/Project/data/traffic_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from threading import Timer\n",
    "\n",
    "class RepeatedTimer(object):\n",
    "    def __init__(self, interval, function, *args, **kwargs):\n",
    "        self._timer     = None\n",
    "        self.interval   = interval\n",
    "        self.function   = function\n",
    "        self.args       = args\n",
    "        self.kwargs     = kwargs\n",
    "        self.is_running = False\n",
    "        self.start()\n",
    "\n",
    "    def _run(self):\n",
    "        self.is_running = False\n",
    "        self.start()\n",
    "        self.function(*self.args, **self.kwargs)\n",
    "\n",
    "    def start(self):\n",
    "        if not self.is_running:\n",
    "            self._timer = Timer(self.interval, self._run)\n",
    "            self._timer.start()\n",
    "            self.is_running = True\n",
    "\n",
    "    def stop(self):\n",
    "        self._timer.cancel()\n",
    "        self.is_running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Timestamp: 2017-03-30 20:04:52\n",
      "Timestamp: 2017-03-30 20:04:57\n",
      "Timestamp: 2017-03-30 20:05:02\n",
      "Timestamp: 2017-03-30 20:05:07\n",
      "Timestamp: 2017-03-30 20:05:12\n",
      "Timestamp: 2017-03-30 20:05:17\n",
      "Timestamp: 2017-03-30 20:05:22\n",
      "Timestamp: 2017-03-30 20:05:27\n",
      "Timestamp: 2017-03-30 20:05:33\n",
      "Timestamp: 2017-03-30 20:05:37\n",
      "Timestamp: 2017-03-30 20:05:42\n",
      "Timestamp: 2017-03-30 20:05:47\n",
      "Timestamp: 2017-03-30 20:05:52\n",
      "Timestamp: 2017-03-30 20:05:57\n",
      "Timestamp: 2017-03-30 20:06:02\n",
      "Timestamp: 2017-03-30 20:06:07\n",
      "Timestamp: 2017-03-30 20:06:12\n",
      "Timestamp: 2017-03-30 20:06:17\n",
      "Timestamp: 2017-03-30 20:06:22\n",
      "Timestamp: 2017-03-30 20:06:27\n",
      "Timestamp: 2017-03-30 20:06:32\n",
      "Timestamp: 2017-03-30 20:06:37\n",
      "Timestamp: 2017-03-30 20:06:42\n",
      "Timestamp: 2017-03-30 20:06:47\n",
      "Timestamp: 2017-03-30 20:06:53\n",
      "Timestamp: 2017-03-30 20:06:57\n",
      "Timestamp: 2017-03-30 20:07:02\n",
      "Timestamp: 2017-03-30 20:07:07\n",
      "Timestamp: 2017-03-30 20:07:12\n",
      "Timestamp: 2017-03-30 20:07:17\n",
      "Timestamp: 2017-03-30 20:07:22\n",
      "Timestamp: 2017-03-30 20:07:27\n",
      "Timestamp: 2017-03-30 20:07:32\n",
      "Timestamp: 2017-03-30 20:07:37\n",
      "Timestamp: 2017-03-30 20:07:42\n",
      "Timestamp: 2017-03-30 20:07:47\n",
      "Timestamp: 2017-03-30 20:07:52\n",
      "Timestamp: 2017-03-30 20:07:57\n",
      "Timestamp: 2017-03-30 20:08:02\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "def scrapeWeb():\n",
    "    \"\"\"\n",
    "    This function will read data from the streaming path specified in the beginning.\n",
    "    It will then write it to an array, and then print it to a text file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Scrape the website\n",
    "    r = requests.get(streamPath, stream = False)  # Stream = false to generate a new array each time\n",
    "    \n",
    "    # Handles missing encodings\n",
    "    if r.encoding is None:\n",
    "        r.encoding = 'utf-8'\n",
    "    \n",
    "    # Array to be written to a file\n",
    "    nycTraffic = []\n",
    "    \n",
    "    # Loads data from requests to array\n",
    "    for line in r.iter_lines(decode_unicode = True):\n",
    "        # Replacing , with ; for multiple coordinates in a single column\n",
    "        updatedLine = line.replace('\"', '').replace(',', ';')\n",
    "        if len(updatedLine.split('\\t')) == 13:  # Filters out rows with missing elements\n",
    "            nycTraffic.append(updatedLine)\n",
    "    \n",
    "    # Filters out items missing rows\n",
    "    nycTraffic = [x for x in nycTraffic if len(x) > 200]\n",
    "\n",
    "    # Writes array to the text file\n",
    "    outputFile = outputFile = outputFilePath+'_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.txt'\n",
    "    with open(outputFile, \"w\") as output:\n",
    "        writer = csv.writer(output, lineterminator = '\\n')\n",
    "        writer.writerows([line.split('\\t') for line in nycTraffic[1:]])\n",
    "    \n",
    "    # Time stamp of when the web was scraped\n",
    "    print('Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now()))\n",
    "    \n",
    "\n",
    "print(\"Starting...\")\n",
    "# Set RepeatedTimer(n) for number of seconds between each run\n",
    "# The first job will start on a delay equal to n\n",
    "rt = RepeatedTimer(5, scrapeWeb) # Auto-starts, no need for rt.start()\n",
    "\n",
    "# Ending\n",
    "try:\n",
    "    # Set sleep(n) for number of seconds for the job to run\n",
    "    sleep(200)  # One hour\n",
    "finally:\n",
    "    rt.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
